{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f509ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a7ccd",
   "metadata": {},
   "source": [
    "## Linear Equations\n",
    "$$\n",
    "Ax = b\n",
    "$$\n",
    "### Solution 1:\n",
    "- Fixed point iteration:\n",
    "\n",
    "    define $G(x) = Ax - b + x = ( A + I)x - b$, and let $G(x)$ be the x in the next iteration\n",
    "    \n",
    "    The iterative process converges if all eigenvalues of (A+I) is within the unit circle. However, this condition is too restrict, which is unlikely to happen in real cases. Therefore, we use Gauss-Jacobi, Gauss-Seidel and other iterative shemes instead.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4646d05d",
   "metadata": {},
   "source": [
    "### Gauss-Jacobi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7ff804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_jacobi(A,b, x):\n",
    "    # Extract the diagonal entries\n",
    "    N = np.diagflat(np.diag(A))\n",
    "    P = N - A\n",
    "    return np.linalg.solve(N, b + P.dot(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9d963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully find solutions: [-1.01708116  0.16642876  0.93157338 -0.72527202]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A = np.array([[3,1,2,-2],[1,5,2,-3],[2,3,6,3],[1,1,2,-5]])\n",
    "x = np.zeros(shape = len(A))\n",
    "b = np.random.uniform(high = 5,size=len(A))\n",
    "epsilon = 1e-14\n",
    "pre_x = np.zeros_like(x)\n",
    "while True:\n",
    "    pre_x = x\n",
    "    x = gauss_jacobi(A,b,x)\n",
    "    if  ((x - pre_x)**2).sum() < epsilon:\n",
    "        print('Successfully find solutions:', x)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1ba4c",
   "metadata": {},
   "source": [
    "### Gauss-Seidel algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f1c8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel(A,b, x,w = 1,shuffle = False):\n",
    "        # Allowing dampening and extrapolating with weight w\n",
    "        # The sequence of solving x's matters for Gauss-Seidel algorithm, we add a shuffle option\n",
    "    if shuffle == True:\n",
    "        values = np.concatenate([A,b.reshape(len(b),-1)],axis=1)\n",
    "        A = values[:,:-1]\n",
    "        b = values[:,-1]\n",
    "    \n",
    "    # Extract the diagonal entries, lower triangular, and upper triangular\n",
    "    L = np.tril(A)\n",
    "    U = A - L\n",
    "        \n",
    "    return w * np.linalg.solve(L, b - U.dot(x)) + (1 - w) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd41053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the two linear system solves into a Linear Solver\n",
    "class LinearSolver:\n",
    "    \n",
    "    # We allow direct call methods in the class\n",
    "    @staticmethod\n",
    "    def gauss_jacobi(A, b, tol=1e-10):\n",
    "        x = np.zeros_like(b)\n",
    "        N = np.diagflat(np.diag(A))\n",
    "        P = A - N\n",
    "        \n",
    "        while True:\n",
    "            pre_x = x.copy()\n",
    "            x = np.linalg.solve(N, b - P.dot(pre_x))\n",
    "            if np.sum((x - pre_x) ** 2) < tol:\n",
    "                print('Successfully found solutions with Jacobi method:', x)\n",
    "                break\n",
    "        \n",
    "        print(\"Results for Ax - b =\", A.dot(x) - b)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def gauss_seidel(A, b, w=1, shuffle=False, tol=1e-10):\n",
    "        x = np.zeros_like(b)\n",
    "        \n",
    "        if shuffle:\n",
    "            indices = np.arange(len(b))\n",
    "            np.random.shuffle(indices)\n",
    "            A = A[indices]\n",
    "            b = b[indices]\n",
    "        \n",
    "        L = np.tril(A)\n",
    "        U = A - L\n",
    "        \n",
    "        while True:\n",
    "            pre_x = x.copy()\n",
    "            x = w * np.linalg.solve(L, b - U.dot(pre_x)) + (1 - w) * pre_x\n",
    "            if np.sum((x - pre_x) ** 2) < tol:\n",
    "                print('Successfully found solutions with Gauss-Seidel method:', x)\n",
    "                break\n",
    "        \n",
    "        print(\"Results for Ax - b =\", A.dot(x) - b)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "913ad0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,.5,.3],[.6,1,.1],[.2,.4,1]])\n",
    "b = np.array([5.,7.,4.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24bd7748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully found solutions with Jacobi method: [1.67155639 5.86510467 1.31964982]\n",
      "Results for Ax - b = [3.67428675e-06 3.48811842e-06 2.97013887e-06]\n",
      "Successfully found solutions with Gauss-Seidel method: [1.67155553 5.86510185 1.31964815]\n",
      "Results for Ax - b = [ 9.00075156e-07 -1.41752707e-08  0.00000000e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.67155553, 5.86510185, 1.31964815])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_solver = LinearSolver()\n",
    "lin_solver.gauss_jacobi(A,b)\n",
    "lin_solver.gauss_seidel(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cfc0e0",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdcb8fe",
   "metadata": {},
   "source": [
    "### Polytope\n",
    "- Polytope method can be used for any $R^n$ functions, regardless of continuity property\n",
    "- Polytope can guarantee a solution but cannot guarantee a global minimum (maximum)\n",
    "- If the objective is rough, Polytope method is advised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646ffab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polytope_algorithm(f, simplex, epsilon):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Perform the Polytope Algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    f (function): The objective function to minimize.\n",
    "    simplex (numpy array): Initial simplex, an (n+1)x(n) array.\n",
    "    epsilon (float): Stopping rule parameter.\n",
    "    \n",
    "    Returns:\n",
    "    numpy array: The optimized vertex of the simplex.\n",
    "    \"\"\"\n",
    "    \n",
    "    n = simplex.shape[0]\n",
    "    \n",
    "    while True:\n",
    "        # Step 1: Reorder the simplex vertices so that f(x^1) >= f(x^2) >= ... >= f(x^{n+1})\n",
    "        simplex = np.array(sorted(simplex, key=lambda x: f(x), reverse=True))\n",
    "        # Step 2: Find the least i such that f(x^i) > f(y^i) where y^i is the reflection of x^i\n",
    "        for i in range(n):\n",
    "            # We shrink the distance of the reflection\n",
    "            reflected = 1e-3 * np.mean(np.delete(initial_simplex,i,0)) + simplex[i]\n",
    "            # The first element that exceeds the function value of the reflected\n",
    "            if f(simplex[i]) > f(reflected):\n",
    "                simplex[i] = reflected\n",
    "                break\n",
    "        # Step 3: Stopping rule, when the simplex is small enough\n",
    "        if np.sum(abs(simplex[-1] - simplex[0])) < epsilon:\n",
    "            return simplex[-1]  # Return the best vertex\n",
    "        # Step 4: Shrink simplex\n",
    "        simplex = .5 * simplex[-1] + 0.5 * simplex\n",
    "\n",
    "# Example usage:\n",
    "def objective_function(x):\n",
    "    return np.sum((x - np.array([1.3, 0.8,.3]))**2)  # Example: minimize the sum of squares\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "cca16d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized vertex: [1.21677517 0.71625434 0.46697049]\n"
     ]
    }
   ],
   "source": [
    "# For a 3-dimensional problem, simplex (the convex hull) has three vertex\n",
    "initial_simplex = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "\n",
    "\n",
    "result = polytope_algorithm(objective_function, initial_simplex, epsilon=1e-14)\n",
    "print(\"Optimized vertex:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f5918",
   "metadata": {},
   "source": [
    "### Newton Method\n",
    "- Iteration scheme: $x^{k + 1} = x^k - H^{-1}(x^k) (\\nabla f(x^k))^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b02311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal solution: [10. 14.]\n"
     ]
    }
   ],
   "source": [
    "# For simplicity, I show a 2 dimensional case, and I write a BFGS optimizer more explicitly below \n",
    "x = np.array([1.0,5.0])\n",
    "delta = 1e-10\n",
    "# Newton's method\n",
    "while 1:\n",
    "    print('Current (x,y) = ', x[0], x[1])\n",
    "    fx = pi(x)\n",
    "    grads = grad_func(x)\n",
    "    H = hessian(pi)(x)\n",
    "    s = np.linalg.solve(H, -grads.reshape(-1,1)).flatten()\n",
    "    \n",
    "    if (s**2).sum() < epsilon * (1 + (x**2).sum()):\n",
    "        print('Iteration ends')\n",
    "        if (grads**2).sum() > delta  * (1 + np.abs(fx)):\n",
    "            print('Not optimum')\n",
    "        else:\n",
    "            print('reach an optimum')\n",
    "        print('Success')\n",
    "        break\n",
    "    x = x + s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846bee61",
   "metadata": {},
   "source": [
    "### Quasi-Newton method\n",
    "#### BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3d7235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad, hessian\n",
    "\n",
    "class BFGS:\n",
    "    \"\"\"\n",
    "    Description: This an example of a BFGS optimizer. \n",
    "    For faster convergence, I comment out the delta criterion\n",
    "    \"\"\"\n",
    "    def __init__(self, func, x, epsilon=1e-12,delta = 1e-10):\n",
    "        self.func = func\n",
    "        self.x = np.array(x, dtype=float)\n",
    "        self.epsilon = epsilon\n",
    "        self.delta = delta\n",
    "        self.H = np.eye(len(x))\n",
    "        self.grad_func = grad(func)\n",
    "        self.hessian_func = hessian(func)\n",
    "        \n",
    "    def line_search(self, s, c1=0.6, c2=0.8):\n",
    "        a = 0.5\n",
    "        fx = self.func(self.x)\n",
    "        grads = self.grad_func(self.x)\n",
    "        \n",
    "        while True:\n",
    "            new_x = self.x + a * s\n",
    "            new_grads = self.grad_func(new_x)\n",
    "            new_fx = self.func(new_x)\n",
    "            \n",
    "            if (new_fx <= fx + c1 * a * (grads.dot(s)) and \n",
    "                np.abs(new_grads.dot(s)) < np.abs(c2 * (grads.dot(s)))):\n",
    "                return a, new_x, new_grads,new_fx\n",
    "            a *= 2\n",
    "            if a > 4:\n",
    "                return 4, new_x, new_grads,new_fx\n",
    "\n",
    "    def update_hessian(self, z, y):\n",
    "        H = self.H\n",
    "        term1 = H - (H.dot(z.reshape(-1, 1)).dot(z.reshape(1, -1)).dot(H)) / (z.dot(H).dot(z))\n",
    "        term2 = (y.reshape(-1, 1).dot(y.reshape(1, -1))) / (y.dot(z))\n",
    "        return term1 + term2\n",
    "\n",
    "    def optimize(self):\n",
    "        while True:\n",
    "            fx = self.func(self.x)\n",
    "            grads = self.grad_func(self.x)\n",
    "            H = self.hessian_func(self.x)\n",
    "            s = np.linalg.solve(H, -grads.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            lda, x_new, new_grads,new_fx = self.line_search(s)\n",
    "            z = lda * s\n",
    "            y = new_grads - grads\n",
    "            print('Current x: ',self.x)\n",
    "            self.x = x_new  # Update x to the new position calculated by line_search\n",
    "            self.H = self.update_hessian(z, y)\n",
    "\n",
    "            print('Current Function Value= ', fx)\n",
    "            if (lda < self.delta) or ((z**2).sum() < self.epsilon * (1 + (self.x**2).sum())):\n",
    "                print('Iteration ends')\n",
    "#                 if (grads**2).sum() > self.delta * (1 + np.abs(fx)):\n",
    "#                     print('Not optimum')\n",
    "#                 else:\n",
    "#                     print('Reached an optimum')\n",
    "                print('Success')\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc42099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current x:  [0.72993383 0.28998015 0.10239402]\n",
      "Current Function Value=  95.50570054925159\n",
      "Current x:  [16.42171173  6.5238385   2.30361295]\n",
      "Current Function Value=  23.87642513731291\n",
      "Current x:  [24.26760068  9.64076767  3.40422242]\n",
      "Current Function Value=  5.969106284328232\n",
      "Current x:  [28.19054516 11.19923226  3.95452715]\n",
      "Current Function Value=  1.492276571082058\n",
      "Current x:  [30.1520174  11.97846455  4.22967952]\n",
      "Current Function Value=  0.3730691427705145\n",
      "Current x:  [31.13275351 12.3680807   4.3672557 ]\n",
      "Current Function Value=  0.09326728569262754\n",
      "Current x:  [31.62312157 12.56288877  4.43604379]\n",
      "Current Function Value=  0.023316821423157157\n",
      "Current x:  [31.8683056  12.66029281  4.47043784]\n",
      "Current Function Value=  0.005829205355788747\n",
      "Current x:  [31.99089762 12.70899483  4.48763486]\n",
      "Current Function Value=  0.0014573013389473902\n",
      "Current x:  [32.05219363 12.73334584  4.49623337]\n",
      "Current Function Value=  0.0003643253347367797\n",
      "Current x:  [32.08284163 12.74552134  4.50053263]\n",
      "Current Function Value=  9.108133368422884e-05\n",
      "Current x:  [32.09816563 12.75160909  4.50268226]\n",
      "Current Function Value=  2.2770333421048733e-05\n",
      "Current x:  [32.10582763 12.75465297  4.50375707]\n",
      "Current Function Value=  5.692583355262183e-06\n",
      "Current x:  [32.10965863 12.75617491  4.50429448]\n",
      "Current Function Value=  1.4231458388176649e-06\n",
      "Current x:  [32.11157413 12.75693588  4.50456318]\n",
      "Current Function Value=  3.557864597022971e-07\n",
      "Current x:  [32.11253188 12.75731636  4.50469753]\n",
      "Current Function Value=  8.894661492557427e-08\n",
      "Current x:  [32.11301076 12.7575066   4.50476471]\n",
      "Current Function Value=  2.223665373139357e-08\n",
      "Current x:  [32.1132502  12.75760172  4.5047983 ]\n",
      "Current Function Value=  5.559163433245727e-09\n",
      "Current x:  [32.11336991 12.75764929  4.50481509]\n",
      "Current Function Value=  1.3897908582452092e-09\n",
      "Current x:  [32.11342977 12.75767307  4.50482349]\n",
      "Current Function Value=  3.474477145944135e-10\n",
      "Iteration ends\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Simple Example\n",
    "def fun(x):\n",
    "    x0, x1,x2 = x\n",
    "    u = x0**(.3) * x1**(.2)*x2**(.5)\n",
    "    return (u-10)**2\n",
    "\n",
    "bfgs = BFGS(func= fun, x=np.random.uniform(size=3))\n",
    "bfgs.optimize()\n",
    "\n",
    "## You can find a more useful example in the script ``logit_example'' in repo ``DiscreteChoiceModel_2024Summer'', \n",
    "## where I use BFGS optimizer to estimate the plain logit model using maximum likelihood estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6511f0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current x:  [0.1619784  0.56297325 0.02029818]\n",
      "Current Function Value=  1.429507938600607\n",
      "Current x:  [0.7309892  0.68148663 0.16014909]\n",
      "Current Function Value=  0.3573769846501518\n",
      "Current x:  [1.0154946  0.74074331 0.23007454]\n",
      "Current Function Value=  0.089344246162538\n",
      "Current x:  [1.1577473  0.77037166 0.26503727]\n",
      "Current Function Value=  0.02233606154063453\n",
      "Current x:  [1.22887365 0.78518583 0.28251864]\n",
      "Current Function Value=  0.0055840153851586145\n",
      "Current x:  [1.26443683 0.79259291 0.29125932]\n",
      "Current Function Value=  0.0013960038462896458\n",
      "Current x:  [1.28221841 0.79629646 0.29562966]\n",
      "Current Function Value=  0.0003490009615724071\n",
      "Current x:  [1.29110921 0.79814823 0.29781483]\n",
      "Current Function Value=  8.72502403930998e-05\n",
      "Current x:  [1.2955546  0.79907411 0.29890741]\n",
      "Current Function Value=  2.1812560098273964e-05\n",
      "Current x:  [1.2977773  0.79953706 0.29945371]\n",
      "Current Function Value=  5.453140024567997e-06\n",
      "Current x:  [1.29888865 0.79976853 0.29972685]\n",
      "Current Function Value=  1.3632850061417376e-06\n",
      "Current x:  [1.29944433 0.79988426 0.29986343]\n",
      "Current Function Value=  3.408212515355502e-07\n",
      "Current x:  [1.29972216 0.79994213 0.29993171]\n",
      "Current Function Value=  8.520531288395945e-08\n",
      "Current x:  [1.29986108 0.79997107 0.29996586]\n",
      "Current Function Value=  2.1301328221018814e-08\n",
      "Current x:  [1.29993054 0.79998553 0.29998293]\n",
      "Current Function Value=  5.3253320552367255e-09\n",
      "Current x:  [1.29996527 0.79999277 0.29999146]\n",
      "Current Function Value=  1.3313330138009962e-09\n",
      "Current x:  [1.29998264 0.79999638 0.29999573]\n",
      "Current Function Value=  3.3283325344622864e-10\n",
      "Current x:  [1.29999132 0.79999819 0.29999787]\n",
      "Current Function Value=  8.32083133636035e-11\n",
      "Current x:  [1.29999566 0.7999991  0.29999893]\n",
      "Current Function Value=  2.080207834009655e-11\n",
      "Current x:  [1.29999783 0.79999955 0.29999947]\n",
      "Current Function Value=  5.200519584512552e-12\n",
      "Iteration ends\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Also, we can use BFGS to solve the polytope example\n",
    "bfgs = BFGS(func= objective_function, x=np.random.uniform(size=3))\n",
    "bfgs.optimize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc271a4",
   "metadata": {},
   "source": [
    "## Nonlinear Equations\n",
    "- General forms for a non-linear system: $f:R^n \\rightarrow R^n$\n",
    "\n",
    "zeros of f: $f(x) = 0$\n",
    "\n",
    "fixed points of f: $ f(x) = x$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e4e67",
   "metadata": {},
   "source": [
    "### One-dimension\n",
    "#### Bisection (linear convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a3a31ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without losing generality, we assume a zero point exists between (0,10]\n",
    "epsilon = 1e-10\n",
    "def bisect(fun,a = 0.1):\n",
    "    init_fa = fun(a)\n",
    "    for potential_b in np.arange(a,4,0.1):\n",
    "        if fun(potential_b) * init_fa < 1e-10:\n",
    "            b = potential_b\n",
    "            break\n",
    "    else:\n",
    "        print('No potential b\\'s satisfy initialization criterion, choose another b range...')\n",
    "        return -1\n",
    "        \n",
    "    while True:\n",
    "        interm = (a+b)/2\n",
    "        fa = fun(a)\n",
    "        fb = fun(b)\n",
    "        if fa * fun(interm) <1e-10:\n",
    "            b = interm\n",
    "        else:\n",
    "            a = interm\n",
    "        print(interm)\n",
    "        if abs(b - a) < epsilon:\n",
    "            print('zero point has been found: ', interm)\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71747715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: we consider demand function, D = 2/p + 3; while supply function, S = 4p**3 - 2.\n",
    "# Therefore, the excess demand function, ED = 2/p + 3 - (4 * exp(p) - 2)\n",
    "\n",
    "def ed(p):\n",
    "    return 2/p + 3 - (4*np.exp(p) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "44913cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n",
      "0.775\n",
      "0.6625000000000001\n",
      "0.71875\n",
      "0.690625\n",
      "0.6765625000000001\n",
      "0.68359375\n",
      "0.687109375\n",
      "0.6853515625\n",
      "0.68447265625\n",
      "0.684033203125\n",
      "0.6838134765625\n",
      "0.68370361328125\n",
      "0.683758544921875\n",
      "0.6837310791015625\n",
      "0.6837448120117188\n",
      "0.6837379455566406\n",
      "0.6837413787841797\n",
      "0.6837396621704102\n",
      "0.6837388038635254\n",
      "0.6837392330169678\n",
      "0.683739447593689\n",
      "0.6837393403053285\n",
      "0.6837393939495087\n",
      "0.6837394207715988\n",
      "0.6837394341826439\n",
      "0.6837394274771214\n",
      "0.6837394308298826\n",
      "0.6837394325062633\n",
      "0.6837394316680729\n",
      "0.6837394312489777\n",
      "0.6837394310394302\n",
      "0.6837394309346565\n",
      "0.6837394309870434\n",
      "zero point has been found:  0.6837394309870434\n"
     ]
    }
   ],
   "source": [
    "bisect(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f0ea80",
   "metadata": {},
   "source": [
    "#### Newton's method (one-dimension case)\n",
    "- Linear approximation: $g(x) = f'(x_k)(x - x_k) + f(x_k)$\n",
    "- Iteration scheme: $x_{k + 1} = x_k - \\frac{f(x_k)}{f'(x_k)}$\n",
    "- With a hope that the sequence $x_k$ will converge to the zero of $f$ (quadratically convergent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2595a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(fun,x0 = 0.1):\n",
    "    epsilon = 1e-10\n",
    "    delta = 1e-10\n",
    "    x = x0\n",
    "    grad_fun = grad(fun)\n",
    "    while True:\n",
    "        s = fun(x)/ grad_fun(x)\n",
    "        x -= s\n",
    "        print(x)\n",
    "        if abs(s)<epsilon * (1 + abs(x)):\n",
    "            print('Iteration ends......')\n",
    "            if abs(fun(x)) < delta:\n",
    "                print('Solution has been found: ', x)\n",
    "            else:\n",
    "                print('No solution has been found')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f956139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2006713995766063\n",
      "0.385396411392974\n",
      "0.6081124116895442\n",
      "0.6818824743584165\n",
      "0.6837387720542631\n",
      "0.6837394309346968\n",
      "0.6837394309347784\n",
      "Iteration ends......\n",
      "Solution has been found:  0.6837394309347784\n"
     ]
    }
   ],
   "source": [
    "newton(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f7909e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.401580009820094e-05"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = 1e-5\n",
    "p1 = 0\n",
    "fun(lb) + grad_fun(lb) * (p1 - lb) + (p1 - lb)**2 * grad(grad_fun)(lb)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3289b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple CGE exmple with two consumers and two products\n",
    "# Following Walras' law, we only need to consider (n-1) market and we normalize p1 + p2 = 1\n",
    "r = -5\n",
    "a12 = 1\n",
    "a21 = 1\n",
    "a11 = 1024\n",
    "a22 = 1024\n",
    "e11 = 12\n",
    "e22 = 12\n",
    "e21 = 1\n",
    "e12 = 1\n",
    "\n",
    "def fun(p1):\n",
    "    p2 = 1 - p1\n",
    "    x12 = (p1 * e11 + p2 * e12)/(p1 * (p1 * a12/p2/a11)**(1/r) + p2)\n",
    "    x22 = (p1 * e21 + p2 * e22)/(p1 * (p1 * a22/p2/a21)**(1/r) + p2)\n",
    "    return x12 + x22 - e12 - e22\n",
    "\n",
    "\n",
    "\n",
    "# Since price has to be non-negative,a.k.a., limited domain, we replace original function with fun_tilde\n",
    "grad_fun = grad(fun)\n",
    "def fun_tilde(p1):\n",
    "    lb = 1e-5\n",
    "    ub = 1 - 1e-5\n",
    "    if p1 < lb:\n",
    "        return fun(lb) + grad_fun(lb) * (p1 - lb) + (p1 - lb)**2 * grad(grad_fun)(lb)/2\n",
    "    elif p1 > ub:\n",
    "        return fun(ub) + grad_fun(ub) * (p1 - ub) + (p1 - ub)**2 * grad(grad_fun)(ub)/2\n",
    "    else:\n",
    "        return fun(p1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4378ccff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n",
      "0.45\n",
      "0.475\n",
      "0.4875\n",
      "0.49375\n",
      "0.496875\n",
      "0.4984375\n",
      "0.49921875\n",
      "0.499609375\n",
      "0.4998046875\n",
      "0.49990234375\n",
      "0.499951171875\n",
      "0.4999755859375\n",
      "0.49998779296875\n",
      "0.49998168945312504\n",
      "0.4999847412109375\n",
      "0.49998321533203127\n",
      "0.49998245239257816\n",
      "0.49998207092285163\n",
      "0.49998188018798834\n",
      "0.49998178482055666\n",
      "0.49998173713684085\n",
      "0.499981713294983\n",
      "0.499981701374054\n",
      "0.4999816954135895\n",
      "0.49998169243335727\n",
      "0.4999816909432412\n",
      "0.4999816901981831\n",
      "0.49998168982565405\n",
      "0.49998168963938955\n",
      "0.4999816895462573\n",
      "zero point has been found:  0.4999816895462573\n"
     ]
    }
   ],
   "source": [
    "# This CGE has three equilibria, we can get all of them by setting different initial values\n",
    "bisect(fun,a = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ef427e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11254257722463024\n",
      "0.1129234593732251\n",
      "0.11292384712759874\n",
      "0.11292384712800163\n",
      "Iteration ends......\n",
      "Solution has been found:  0.11292384712800163\n"
     ]
    }
   ],
   "source": [
    "newton(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e9d76ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8889915781252126\n",
      "0.8871218805566008\n",
      "0.8870761793372882\n",
      "0.887076152872008\n",
      "0.8870761528719988\n",
      "Iteration ends......\n",
      "Solution has been found:  0.8870761528719988\n"
     ]
    }
   ],
   "source": [
    "newton(fun,x0=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3db86da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.021535345443671083\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vq/y8sw0dx95kg8d24dbz5s_kt80000gn/T/ipykernel_55479/2275684538.py:15: RuntimeWarning: invalid value encountered in scalar power\n",
      "  x12 = (p1 * e11 + p2 * e12)/(p1 * (p1 * a12/p2/a11)**(1/r) + p2)\n",
      "/var/folders/vq/y8sw0dx95kg8d24dbz5s_kt80000gn/T/ipykernel_55479/2275684538.py:16: RuntimeWarning: invalid value encountered in scalar power\n",
      "  x22 = (p1 * e21 + p2 * e22)/(p1 * (p1 * a22/p2/a21)**(1/r) + p2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vq/y8sw0dx95kg8d24dbz5s_kt80000gn/T/ipykernel_55479/3928575377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/vq/y8sw0dx95kg8d24dbz5s_kt80000gn/T/ipykernel_55479/2138282325.py\u001b[0m in \u001b[0;36mnewton\u001b[0;34m(fun, x0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgrad_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mgrad_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n\u001b[1;32m     31\u001b[0m                         \"Try jacobian, elementwise_grad or holomorphic_grad.\")\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0munary_to_nary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(g, end_node)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoposort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mingrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moutgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_outgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mingrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/core.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mvjp_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_0_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mvjp_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_1_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvjp_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mvjps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvjps_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munbroadcast_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0mtarget_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munbroadcast_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/numpy/numpy_vjps.py\u001b[0m in \u001b[0;36munbroadcast\u001b[0;34m(x, target_meta, broadcast_idx)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_iscomplex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtarget_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbroadcast_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0margvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mndim\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Suffer limited domain issue\n",
    "newton(fun,x0=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "998f7668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.021535345443671083\n",
      "-0.010743556341296746\n",
      "-0.005347719412701803\n",
      "-0.0026499161892814507\n",
      "-0.001301245024871699\n",
      "-0.0006273700617935158\n",
      "-0.00029135161970622077\n",
      "-0.00012516304547408863\n",
      "-4.557548683428039e-05\n",
      "-1.1855598452631391e-05\n",
      "-2.4123860850689766e-06\n",
      "-1.534001841631761e-06\n",
      "-1.526268002423859e-06\n",
      "-1.5262674027934035e-06\n",
      "Iteration ends......\n",
      "Solution has been found:  -1.5262674027934035e-06\n"
     ]
    }
   ],
   "source": [
    "# Avoided the limited domain issue, but point x=0 is not a solution\n",
    "newton(fun_tilde,x0=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3c1fc9",
   "metadata": {},
   "source": [
    "### Multivariate nonlinear equation system\n",
    "- Suppose $f: R^n \\rightarrow R^n$ and we want to solve $f(x) = 0$, where \n",
    "\\begin{align}\n",
    "    f(x) =0:~ & \\begin{bmatrix}\n",
    "           f^1(x_1,x_2,\\dots,x_n)=0 \\\\\n",
    "           f^2(x_1,x_2,\\dots,x_n)=0 \\\\\n",
    "           \\vdots \\\\\n",
    "            f^n(x_1,x_2,\\dots,x_n)=0 \\\\\n",
    "         \\end{bmatrix}\n",
    "  \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a852d5",
   "metadata": {},
   "source": [
    "#### Gauss-Jacobi Algorithm\n",
    "- Similar to Gauss-Jacobi algorithm in linear system, update x in the (k+1)-th iteration using one equation\n",
    "\\begin{bmatrix}\n",
    "           f^1(x^{k+1}_1,x^k_2,\\dots,x^k_n)=0 \\\\\n",
    "           f^2(x^k_1,x^{k+1}_2,\\dots,x^k_n)=0 \\\\\n",
    "           \\vdots \\\\\n",
    "            f^n(x^k_1,x^k_2,\\dots,x^{k+1}_n)=0 \\\\\n",
    "         \\end{bmatrix}\n",
    "\n",
    "- For each equation, we apply one-dimensional Newton's method\n",
    "$$\n",
    "x^{k+1}_i = x^k_i - \\frac{f^i(x^k)}{f^i_{x_i}(x_k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d19363cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "43af11b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e69d130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fun(p):\n",
    "    p1,p2 = p\n",
    "    x12 = (p1 * e11 + p2 * e12)/(p1 * (p1 * a12/p2/a11)**(1/r) + p2)\n",
    "    x22 = (p1 * e21 + p2 * e22)/(p1 * (p1 * a22/p2/a21)**(1/r) + p2)\n",
    "    return np.array([x12 + x22 - e12 - e22,x12 + x22 - e12 - e22])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a1f27288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function autograd.wrap_util.unary_to_nary.<locals>.nary_operator.<locals>.nary_f(*args, **kwargs)>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([0.5,0.5])\n",
    "jacobian(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "5fb3e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(params):\n",
    "    x,y = params\n",
    "    return np.array([y-np.exp(x), x * (x**2 - 3*y)**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f787d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_inv = np.zeros(2)\n",
    "inputs = np.array([0.5,0.5])\n",
    "jac_func = jacobian(fun)\n",
    "jac_inv = 1/np.diag(jac_func(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "392f3481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.64872127,  1.        ],\n",
       "       [ 0.3125    ,  3.75      ]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac_func(np.array([0.5,0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "fbbbdae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_jacobi(fun, x0 = np.array([0.1,0.1])):\n",
    "    epsilon = 1e-10\n",
    "    delta = 1e-10\n",
    "    jac_func = jacobian(fun)\n",
    "    x = x0\n",
    "    while True:\n",
    "        fx = fun(x)\n",
    "        jac_inv = 1/np.diag(jac_func(x))\n",
    "        s = fx * jac_inv\n",
    "        x -= s\n",
    "        print(x)\n",
    "        if (s**2).sum() < epsilon * (1 + (s**2).sum()):\n",
    "            print('Iteration ends......')\n",
    "            if (fun(x)**2).sum() < delta:\n",
    "                print('Solution has been found: ', x)\n",
    "            else:\n",
    "                print('No solution has been found')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "64fbfa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.80951626  0.05166667]\n",
      "[-1.69343051  0.13505276]\n",
      "[-1.95899952  0.54547753]\n",
      "[0.90965144 0.91235195]\n",
      "[0.27702323 0.59408693]\n",
      "[-0.27263696  0.30983378]\n",
      "[-0.86569405  0.16730537]\n",
      "[-1.46806689  0.20855705]\n",
      "[-1.56275499  0.46348193]\n",
      "[-0.35104249  0.63877482]\n",
      "[-0.44363239  0.33992588]\n",
      "[-0.91390634  0.20276456]\n",
      "[-1.40820218  0.24058641]\n",
      "[-1.424541    0.45079877]\n",
      "[-0.55104394  0.5636189 ]\n",
      "[-0.57312944  0.33241768]\n",
      "[-0.98348382  0.22095507]\n",
      "[-1.39270412  0.27168427]\n",
      "[-1.29897894  0.45911293]\n",
      "[-0.61607661  0.51078085]\n",
      "[-0.67028975  0.31864882]\n",
      "[-1.04739387  0.2342058 ]\n",
      "[-1.37985735  0.29994189]\n",
      "[-1.18778791  0.46730533]\n",
      "[-0.65511151  0.46879268]\n",
      "[-0.75251814  0.30592486]\n",
      "[-1.1032423   0.24734302]\n",
      "[-1.35776967  0.32652877]\n",
      "[-1.08838476  0.4705208 ]\n",
      "[-0.69118558  0.43269063]\n",
      "[-0.82750019  0.29596823]\n",
      "[-1.15044532  0.26211021]\n",
      "[-1.322282    0.35164251]\n",
      "[-1.00292858  0.4672262 ]\n",
      "[-0.72915119  0.40125739]\n",
      "[-0.89721622  0.28923894]\n",
      "[-1.18778089  0.27878562]\n",
      "[-1.27342122  0.37453005]\n",
      "[-0.93520441  0.45753196]\n",
      "[-0.76953459  0.37453386]\n",
      "[-0.96100538  0.28596418]\n",
      "[-1.2134025   0.29690398]\n",
      "[-1.21434605  0.39384293]\n",
      "[-0.88784732  0.44269418]\n",
      "[-0.81214772  0.3527259 ]\n",
      "[-1.0175476  0.2862936]\n",
      "[-1.22554437  0.31571399]\n",
      "[-1.1502163   0.40818349]\n",
      "[-0.86081522  0.42459134]\n",
      "[-0.85661935  0.33579614]\n",
      "[-1.06575726  0.29019752]\n",
      "[-1.22330326  0.33440518]\n",
      "[-1.08686235  0.4166144 ]\n",
      "[-0.85161878  0.4051855 ]\n",
      "[-0.90209198  0.32346851]\n",
      "[-1.1048217   0.29736258]\n",
      "[-1.2071774   0.35211979]\n",
      "[-1.02967741  0.41893944]\n",
      "[-0.85657895  0.38617565]\n",
      "[-0.94710054  0.31537574]\n",
      "[-1.13399144  0.30718778]\n",
      "[-1.17924037  0.36791665]\n",
      "[-0.9828111  0.4157263]\n",
      "[-0.87200837  0.36884943]\n",
      "[-0.98982771  0.31115781]\n",
      "[-1.15257334  0.31887205]\n",
      "[-1.14291903  0.38084025]\n",
      "[-0.94863874  0.40813078]\n",
      "[-0.89476662  0.3540513 ]\n",
      "[-1.0284864  0.3104602]\n",
      "[-1.1601822   0.33152748]\n",
      "[-1.10243896  0.39010086]\n",
      "[-0.92764943  0.39761237]\n",
      "[-0.92226323  0.34222843]\n",
      "[-1.06156697  0.31287579]\n",
      "[-1.15707516  0.34425863]\n",
      "[-1.06212034  0.39526647]\n",
      "[-0.91881304  0.38564984]\n",
      "[-0.95225355  0.33352782]\n",
      "[-1.08790178  0.31789505]\n",
      "[-1.14437658  0.35620257]\n",
      "[-1.02572849  0.39636758]\n",
      "[-0.92020914  0.37353695]\n",
      "[-0.98270042  0.32789928]\n",
      "[-1.10666465  0.32489966]\n",
      "[-1.12408535  0.36656761]\n",
      "[-0.9960099   0.39387845]\n",
      "[-0.92960084  0.36227851]\n",
      "[-1.01176906  0.32516554]\n",
      "[-1.11741344  0.33319555]\n",
      "[-1.09885564  0.37469991]\n",
      "[-0.97448234  0.38859724]\n",
      "[-0.94477925  0.35256792]\n",
      "[-1.037888    0.32505193]\n",
      "[-1.12018577  0.34206122]\n",
      "[-1.07162324  0.38016663]\n",
      "[-0.96149268  0.38147938]\n",
      "[-0.96369605  0.34481772]\n",
      "[-1.05980216  0.32719387]\n",
      "[-1.11558608  0.35079371]\n",
      "[-1.0451896  0.3828189]\n",
      "[-0.95647649  0.37347967]\n",
      "[-0.98449179  0.33921438]\n",
      "[-1.076601    0.33114454]\n",
      "[-1.10479524  0.35875056]\n",
      "[-1.02186855  0.38280403]\n",
      "[-0.95829293  0.3654379 ]\n",
      "[-1.00550791  0.33577317]\n",
      "[-1.08774071  0.33639428]\n",
      "[-1.08946986  0.36539378]\n",
      "[-1.0032646   0.38052099]\n",
      "[-0.96551902  0.35801714]\n",
      "[-1.0253122   0.33437973]\n",
      "[-1.09307297  0.34240072]\n",
      "[-1.07154509  0.37033511]\n",
      "[-0.99020823  0.3765357 ]\n",
      "[-0.97665133  0.35168657]\n",
      "[-1.04273048  0.33481793]\n",
      "[-1.09286787  0.34862344]\n",
      "[-1.05298825  0.37337175]\n",
      "[-0.98282893  0.37148325]\n",
      "[-0.99022402  0.34673374]\n",
      "[-1.05687316  0.33679081]\n",
      "[-1.08780481  0.35455888]\n",
      "[-1.03556193  0.37449932]\n",
      "[-0.98071396  0.36598108]\n",
      "[-1.00487692  0.34329052]\n",
      "[-1.06715447  0.33994153]\n",
      "[-1.07891197  0.35977388]\n",
      "[-1.02064524  0.37389545]\n",
      "[-0.98309109  0.36056717]\n",
      "[-1.01940138  0.3413616 ]\n",
      "[-1.07330569  0.34387733]\n",
      "[-1.06745323  0.36393618]\n",
      "[-1.00913986  0.37187749]\n",
      "[-0.98899049  0.35566595]\n",
      "[-1.03277581  0.34085001]\n",
      "[-1.07537863  0.34819598]\n",
      "[-1.05478051  0.36683786]\n",
      "[-1.00146252  0.36884592]\n",
      "[-0.99736793  0.35157749]\n",
      "[-1.04419336  0.34157921]\n",
      "[-1.07373067  0.3525129 ]\n",
      "[-1.04218058  0.36840604]\n",
      "[-0.99760464  0.36522642]\n",
      "[-1.00719155  0.34848238]\n",
      "[-1.05308132  0.34331366]\n",
      "[-1.06898301  0.35648687]\n",
      "[-1.0307449   0.36869755]\n",
      "[-0.99722921  0.36142128]\n",
      "[-1.01750268  0.34645499]\n",
      "[-1.05911191  0.34577945]\n",
      "[-1.0619501   0.35984273]\n",
      "[-1.02128306  0.3678777 ]\n",
      "[-0.99977673  0.35777536]\n",
      "[-1.02745957  0.34547993]\n",
      "[-1.06220282  0.3486855 ]\n",
      "[-1.05354768  0.36238855]\n",
      "[-1.0142872   0.36618806]\n",
      "[-1.00456125  0.35455712]\n",
      "[-1.03636897  0.34546911]\n",
      "[-1.06250444  0.35174466]\n",
      "[-1.04469299  0.36402495]\n",
      "[-1.00994272  0.36390971]\n",
      "[-1.01084907  0.35195224]\n",
      "[-1.04370782  0.34627876]\n",
      "[-1.06037077  0.35469371]\n",
      "[-1.03621347  0.36474455]\n",
      "[-1.00817206  0.36132867]\n",
      "[-1.01791948  0.35006615]\n",
      "[-1.04913553  0.34772642]\n",
      "[-1.05631337  0.35731077]\n",
      "[-1.02877706  0.36462171]\n",
      "[-1.00869591  0.3587079 ]\n",
      "[-1.02511067  0.34893185]\n",
      "[-1.05249665  0.34960791]\n",
      "[-1.05094181  0.35942882]\n",
      "[-1.02285183  0.36379419]\n",
      "[-1.01109845  0.35626807]\n",
      "[-1.03185341  0.34852071]\n",
      "[-1.05381291  0.35171393]\n",
      "[-1.04489762  0.36094391]\n",
      "[-1.01869531  0.36244046]\n",
      "[-1.01488784  0.35417692]\n",
      "[-1.03769462  0.34875468]\n",
      "[-1.05326405  0.35384569]\n",
      "[-1.03879061  0.36181704]\n",
      "[-1.01636894  0.36075618]\n",
      "[-1.0195479   0.35254572]\n",
      "[-1.04231185  0.34951918]\n",
      "[-1.05115748  0.35582859]\n",
      "[-1.03314587  0.36206964]\n",
      "[-1.01576948  0.35893322]\n",
      "[-1.0245799   0.35143121]\n",
      "[-1.04551895  0.35067627]\n",
      "[-1.04788899  0.35752311]\n",
      "[-1.02836716  0.36177344]\n",
      "[-1.01666922  0.35714322]\n",
      "[-1.02953491  0.35084099]\n",
      "[-1.04726314  0.35207752]\n",
      "[-1.04389826  0.35883211]\n",
      "[-1.02471907  0.36103665]\n",
      "[-1.01875811  0.35552652]\n",
      "[-1.0340375   0.35074127]\n",
      "[-1.04761344  0.35357623]\n",
      "[-1.03962443  0.35970377]\n",
      "[-1.02232655  0.35998838]\n",
      "[-1.02168333  0.35418612]\n",
      "[-1.03780144  0.35106586]\n",
      "[-1.04674123  0.35503824]\n",
      "[-1.0354667   0.36013032]\n",
      "[-1.02118834  0.35876371]\n",
      "[-1.02508369  0.35318612]\n",
      "[-1.04063786  0.35172583]\n",
      "[-1.04489423  0.35635077]\n",
      "[-1.03175413  0.36014271]\n",
      "[-1.0211996   0.35749079]\n",
      "[-1.02861803  0.3525535 ]\n",
      "[-1.04245626  0.35261926]\n",
      "[-1.04236639  0.35742881]\n",
      "[-1.0287269   0.35980235]\n",
      "[-1.02217908  0.35628102]\n",
      "[-1.03198708  0.35228219]\n",
      "[-1.04325875  0.35364065]\n",
      "[-1.03946683  0.35821846]\n",
      "[-1.02652928  0.35919111]\n",
      "[-1.02389723  0.35522262]\n",
      "[-1.03494907  0.3523389 ]\n",
      "[-1.04312816  0.35468938]\n",
      "[-1.03649093  0.35869742]\n",
      "[-1.02521298  0.35840095]\n",
      "[-1.02610255  0.35437742]\n",
      "[-1.03732929  0.35266978]\n",
      "[-1.04221117  0.3556769 ]\n",
      "[-1.0336965   0.35887247]\n",
      "[-1.02474839  0.35752431]\n",
      "[-1.0285447   0.35378037]\n",
      "[-1.0390237   0.35320755]\n",
      "[-1.04069803  0.35653215]\n",
      "[-1.03128685  0.35877481]\n",
      "[-1.02504094  0.35664617]\n",
      "[-1.03099333  0.35344124]\n",
      "[-1.03999726  0.35387849]\n",
      "[-1.03880095  0.35720496]\n",
      "[-1.02940164  0.35845372]\n",
      "[-1.02594979  0.35583815]\n",
      "[-1.0332525  0.3533479]\n",
      "[-1.04027736  0.35460907]\n",
      "[-1.03673303  0.35766737]\n",
      "[-1.02811494  0.35796958]\n",
      "[-1.02730694  0.35515485]\n",
      "[-1.03517032  0.35347068]\n",
      "[-1.03994331  0.35533161]\n",
      "[-1.03469008  0.35791282]\n",
      "[-1.02743969  0.357387  ]\n",
      "[-1.02893493  0.35463222]\n",
      "[-1.03664416  0.35376729]\n",
      "[-1.0391129   0.35598883]\n",
      "[-1.03283631  0.35795368]\n",
      "[-1.02733661  0.35676865]\n",
      "[-1.03066221  0.35428774]\n",
      "[-1.03762154  0.35418797]\n",
      "[-1.03792747  0.35653706]\n",
      "[-1.03129519  0.35781744]\n",
      "[-1.02772602  0.35617035]\n",
      "[-1.0323355   0.35412197]\n",
      "[-1.03809722  0.35468042]\n",
      "[-1.03653692  0.35694785]\n",
      "[-1.03014526  0.35754205]\n",
      "[-1.02850094  0.35563757]\n",
      "[-1.03382889  0.35412115]\n",
      "[-1.03810702  0.35519427]\n",
      "[-1.03508584  0.35720817]\n",
      "[-1.02942058  0.3571712 ]\n",
      "[-1.02954005  0.35520339]\n",
      "[-1.03504949  0.35426048]\n",
      "[-1.03771924  0.35568482]\n",
      "[-1.03370224  0.35731928]\n",
      "[-1.02911507  0.35674969]\n",
      "[-1.03071959  0.35488782]\n",
      "[-1.03593987  0.35450772]\n",
      "[-1.03702456  0.35611576]\n",
      "[-1.03248917  0.35729454]\n",
      "[-1.02918936  0.35631958]\n",
      "[-1.0319235   0.35469825]\n",
      "[-1.03647745  0.35482681]\n",
      "[-1.03612541  0.35646099]\n",
      "[-1.0315199   0.35715647]\n",
      "[-1.02957942  0.35591712]\n",
      "[-1.03305135  0.35463086]\n",
      "[-1.0366713   0.35518128]\n",
      "[-1.03512579  0.3567052 ]\n",
      "[-1.03083643  0.3569335 ]\n",
      "[-1.03020558  0.35557071]\n",
      "[-1.03402385  0.35467261]\n",
      "[-1.03655692  0.35553719]\n",
      "[-1.03412246  0.35684364]\n",
      "[-1.03045086  0.3566567 ]\n",
      "[-1.03098145  0.35529984]\n",
      "[-1.03478596  0.35480371]\n",
      "[-1.03618957  0.35586552]\n",
      "[-1.0331979  0.3568809]\n",
      "[-1.03034912  0.35635677]\n",
      "[-1.03182181  0.35511493]\n",
      "[-1.03530769  0.35500018]\n",
      "[-1.03563694  0.35614376]\n",
      "[-1.03241564  0.35682919]\n",
      "[-1.03049623  0.3560616 ]\n",
      "[-1.0326492   0.35501788]\n",
      "[-1.03558281  0.35523633]\n",
      "[-1.03497179  0.35635679]\n",
      "[-1.03181786  0.35670617]\n",
      "[-1.03084243  0.35579443]\n",
      "[-1.03339888  0.35500323]\n",
      "[-1.0356259   0.35548716]\n",
      "[-1.03426523  0.35649708]\n",
      "[-1.03142521  0.35653263]\n",
      "[-1.0313295   0.35557264]\n",
      "[-1.03402208  0.35505975]\n",
      "[-1.03546816  0.35573015]\n",
      "[-1.03358107  0.35656413]\n",
      "[-1.03123844  0.35633037]\n",
      "[-1.03189677  0.3554073 ]\n",
      "[-1.03448745  0.35517214]\n",
      "[-1.03515248  0.35594679]\n",
      "[-1.03297166  0.3565635 ]\n",
      "[-1.03124143  0.35612016]\n",
      "[-1.0324863   0.35530323]\n",
      "[-1.03478105  0.35532294]\n",
      "[-1.03472821  0.35612344]\n",
      "[-1.03247533  0.35650547]\n",
      "[-1.03140513  0.35592028]\n",
      "[-1.03304715  0.35525957]\n",
      "[-1.03490485  0.35549418]\n",
      "[-1.03424617  0.35625177]\n",
      "[-1.03211532  0.35640341]\n",
      "[-1.03169193  0.35574538]\n",
      "[-1.03353834  0.35527073]\n",
      "[-1.03487427  0.35566895]\n",
      "[-1.03375428  0.3563286 ]\n",
      "[-1.03190022  0.35627229]\n",
      "[-1.03205998  0.35560582]\n",
      "[-1.03393065  0.35532754]\n",
      "[-1.03471495  0.35583254]\n",
      "[-1.03329405  0.35635544]\n",
      "[-1.03182554  0.35612715]\n",
      "[-1.03246724  0.35550757]\n",
      "[-1.03420723  0.35541855]\n",
      "[-1.03445914  0.35597337]\n",
      "[-1.03289813  0.35633764]\n",
      "[-1.03187606  0.35598191]\n",
      "[-1.03287487  0.35545232]\n",
      "[-1.03436305  0.35553124]\n",
      "[-1.03414213  0.35608344]\n",
      "[-1.03258899  0.35628338]\n",
      "[-1.0320287   0.35584836]\n",
      "[-1.03324985  0.35543805]\n",
      "[-1.03440363  0.35565324]\n",
      "[-1.03379889  0.35615843]\n",
      "[-1.03237861  0.35620257]\n",
      "[-1.03225567  0.35573555]\n",
      "[-1.03356679  0.35545974]\n",
      "[-1.03434299  0.35577326]\n",
      "[-1.03346129  0.35619753]\n",
      "[-1.03226913  0.3561058 ]\n",
      "[-1.03252736  0.3556495 ]\n",
      "[-1.03380877  0.35551021]\n",
      "[-1.03420124  0.35588187]\n",
      "[-1.03315589  0.35620297]\n",
      "[-1.03225417  0.35600333]\n",
      "[-1.03281502  0.35559311]\n",
      "[-1.03396748  0.35558103]\n",
      "[-1.03400211  0.35597198]\n",
      "[-1.03290266  0.35617938]\n",
      "[-1.03232062  0.35590434]\n",
      "[-1.03309298  0.35556648]\n",
      "[-1.03404258  0.35566343]\n",
      "[-1.03377039  0.35603906]\n",
      "[-1.03271428  0.35613306]\n",
      "[-1.03245081  0.35581633]\n",
      "[-1.03334021  0.35556728]\n",
      "[-1.03404056  0.35574897]\n",
      "[-1.03352981  0.35608113]\n",
      "[-1.03259624  0.35607121]\n",
      "[-1.03262454  0.35574477]\n",
      "[-1.03354132  0.35559129]\n",
      "[-1.03397317  0.35583026]\n",
      "[-1.03330124  0.35609855]\n",
      "[-1.03254749  0.35600118]\n",
      "[-1.03282119  0.35569298]\n",
      "[-1.03368697  0.35563309]\n",
      "[-1.03385571  0.35590134]\n",
      "[-1.03310145  0.35609361]\n",
      "[-1.0325615  0.3559299]\n",
      "[-1.03302136  0.35566216]\n",
      "[-1.03377371  0.3556866 ]\n",
      "[-1.03370527  0.35595798]\n",
      "[-1.0329423   0.35607009]\n",
      "[-1.03262765  0.35586334]\n",
      "[-1.03320833  0.35565165]\n",
      "[-1.03380337  0.35574573]\n",
      "[-1.03353901  0.35599777]\n",
      "[-1.03283057  0.3560327 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0327327   0.35580618]\n",
      "[-1.03336893  0.35565923]\n",
      "[-1.03378214  0.35580484]\n",
      "[-1.03337282  0.35602001]\n",
      "[-1.03276817  0.35598657]\n",
      "[-1.03286228  0.35576163]\n",
      "[-1.03349415  0.35568156]\n",
      "[-1.03371941  0.35585914]\n",
      "[-1.03322018  0.35602554]\n",
      "[-1.0327527   0.35593676]\n",
      "[-1.03300218  0.3557314 ]\n",
      "[-1.03357915  0.35571462]\n",
      "[-1.0336265   0.35590495]\n",
      "[-1.03309143  0.35601643]\n",
      "[-1.03277834  0.35588787]\n",
      "[-1.03313952  0.35571578]\n",
      "[-1.03362312  0.3557541 ]\n",
      "[-1.03351551  0.35593984]\n",
      "[-1.03299341  0.35599564]\n",
      "[-1.03283679  0.35584372]\n",
      "[-1.03326355  0.35571383]\n",
      "[-1.03362865  0.35579584]\n",
      "[-1.03339816  0.35596262]\n",
      "[-1.03292944  0.3559666 ]\n",
      "[-1.03291836  0.35580717]\n",
      "[-1.03336624  0.35572364]\n",
      "[-1.0336011   0.35583612]\n",
      "[-1.03328494  0.35597327]\n",
      "[-1.03289957  0.35593293]\n",
      "[-1.03301296  0.35578005]\n",
      "[-1.03344248  0.35574266]\n",
      "[-1.03354768  0.35587189]\n",
      "[-1.03318441  0.35597274]\n",
      "[-1.03290107  0.35589804]\n",
      "[-1.03311096  0.35576313]\n",
      "[-1.03349007  0.35576794]\n",
      "[-1.03347662  0.35590092]\n",
      "[-1.03310282  0.35596278]\n",
      "[-1.03292908  0.35586496]\n",
      "[-1.0332039   0.35575623]\n",
      "[-1.03350948  0.3557965 ]\n",
      "[-1.03339634  0.35592189]\n",
      "[-1.03304392  0.35594561]\n",
      "[-1.03297733  0.3558361 ]\n",
      "[-1.03328501  0.35575841]\n",
      "[-1.03350338  0.35582552]\n",
      "[-1.03331475  0.3559343 ]\n",
      "[-1.03300906  0.35592371]\n",
      "[-1.03303886  0.35581314]\n",
      "[-1.03334951  0.35576812]\n",
      "[-1.0334761  0.3558526]\n",
      "[-1.03323866  0.35593844]\n",
      "[-1.03299746  0.35589958]\n",
      "[-1.03310667  0.35579708]\n",
      "[-1.03339467  0.35578344]\n",
      "[-1.03343305  0.35587581]\n",
      "[-1.03317342  0.35593522]\n",
      "[-1.03300652  0.35587549]\n",
      "[-1.03317433  0.35578816]\n",
      "[-1.03341975  0.35580228]\n",
      "[-1.0333801   0.35589387]\n",
      "[-1.03312268  0.35592601]\n",
      "[-1.03303242  0.35585341]\n",
      "[-1.03323637  0.35578604]\n",
      "[-1.03342573  0.35582258]\n",
      "[-1.03332303  0.35590608]\n",
      "[-1.03308837  0.35591245]\n",
      "[-1.03307049  0.35583482]\n",
      "[-1.03328861  0.35578985]\n",
      "[-1.03341502  0.35584249]\n",
      "[-1.03326709  0.35591234]\n",
      "[-1.03307079  0.35589632]\n",
      "[-1.03311583  0.3558207 ]\n",
      "[-1.0333283  0.3557984]\n",
      "[-1.03339099  0.35586043]\n",
      "[-1.03321666  0.35591304]\n",
      "[-1.03306884  0.3558793 ]\n",
      "[-1.03316366  0.35581152]\n",
      "[-1.03335411  0.35581028]\n",
      "[-1.0333576   0.35587526]\n",
      "[-1.03317498  0.35590895]\n",
      "[-1.03308033  0.3558629 ]\n",
      "[-1.03320973  0.35580728]\n",
      "[-1.03336604  0.35582403]\n",
      "[-1.03331897  0.35588624]\n",
      "[-1.03314413  0.35590114]\n",
      "[-1.03310229  0.35584837]\n",
      "[-1.03325056  0.35580757]\n",
      "[-1.03336521  0.35583824]\n",
      "[-1.03327903  0.35589306]\n",
      "[-1.03312496  0.35589079]\n",
      "[-1.03313137  0.35583659]\n",
      "[-1.03328365  0.3558117 ]\n",
      "[-1.03335362  0.3558517 ]\n",
      "[-1.0332412  0.3558958]\n",
      "[-1.03311728  0.35587913]\n",
      "[-1.03316413  0.35582812]\n",
      "[-1.03330747  0.35581874]\n",
      "[-1.03333382  0.35586343]\n",
      "[-1.03320825  0.35589485]\n",
      "[-1.03311997  0.3558673 ]\n",
      "[-1.03319736  0.35582313]\n",
      "[-1.03332149  0.3558277 ]\n",
      "[-1.03330867  0.35587273]\n",
      "[-1.0331821   0.35589083]\n",
      "[-1.03313124  0.35585629]\n",
      "[-1.0332283   0.35582151]\n",
      "[-1.03332606  0.35583754]\n",
      "[-1.033281    0.35587923]\n",
      "[-1.03316385  0.35588455]\n",
      "[-1.0331489   0.35584687]\n",
      "[-1.03325479  0.35582287]\n",
      "[-1.03332222  0.35584735]\n",
      "[-1.03325344  0.35588281]\n",
      "[-1.03315379  0.35587685]\n",
      "[-1.03317054  0.35583955]\n",
      "[-1.03327535  0.35582667]\n",
      "[-1.03331155  0.35585632]\n",
      "[-1.03322821  0.35588362]\n",
      "[-1.0331515   0.35586857]\n",
      "[-1.03319381  0.35583462]\n",
      "[-1.0332892   0.35583222]\n",
      "[-1.03329596  0.35586387]\n",
      "[-1.033207    0.35588202]\n",
      "[-1.033156    0.35586046]\n",
      "[-1.03321658  0.35583212]\n",
      "[-1.03329624  0.35583881]\n",
      "[-1.03327744  0.35586959]\n",
      "[-1.03319093  0.3558785 ]\n",
      "[-1.03316588  0.35585317]\n",
      "[-1.03323708  0.35583188]\n",
      "[-1.03329692  0.35584575]\n",
      "[-1.03325794  0.35587329]\n",
      "[-1.03318052  0.35587364]\n",
      "[-1.03317955  0.35584715]\n",
      "[-1.03325398  0.35583357]\n",
      "[-1.03329214  0.35585242]\n",
      "[-1.03323918  0.35587499]\n",
      "[-1.03317577  0.35586803]\n",
      "[-1.03319532  0.35584271]\n",
      "[-1.03326647  0.35583678]\n",
      "[-1.03328312  0.35585832]\n",
      "[-1.03322259  0.35587483]\n",
      "[-1.03317621  0.35586224]\n",
      "[-1.0332116   0.35583996]\n",
      "[-1.03327419  0.35584102]\n",
      "[-1.03327123  0.3558631 ]\n",
      "[-1.03320917  0.35587312]\n",
      "[-1.03318101  0.35585676]\n",
      "[-1.03322699  0.35583888]\n",
      "[-1.03327723  0.35584578]\n",
      "[-1.03325786  0.35586653]\n",
      "[-1.03319954  0.35587023]\n",
      "[-1.03318913  0.355852  ]\n",
      "[-1.03324037  0.3558393 ]\n",
      "[-1.03327606  0.35585059]\n",
      "[-1.03324432  0.35586853]\n",
      "[-1.0331939   0.35586657]\n",
      "[-1.03319942  0.35584822]\n",
      "[-1.03325097  0.35584095]\n",
      "[-1.03327141  0.35585507]\n",
      "[-1.03323173  0.35586917]\n",
      "[-1.03319211  0.35586255]\n",
      "[-1.03321071  0.3558456 ]\n",
      "[-1.03325835  0.35584353]\n",
      "[-1.03326417  0.3558589 ]\n",
      "[-1.03322098  0.35586859]\n",
      "[-1.03319374  0.35585856]\n",
      "[-1.03322193  0.35584416]\n",
      "[-1.03326238  0.35584668]\n",
      "[-1.03325533  0.35586186]\n",
      "[-1.03321265  0.35586703]\n",
      "[-1.03319814  0.35585491]\n",
      "[-1.03323219  0.35584385]\n",
      "[-1.03326326  0.35585005]\n",
      "[-1.03324584  0.35586385]\n",
      "[-1.03320706  0.35586475]\n",
      "[-1.03320453  0.35585185]\n",
      "[-1.03324079  0.35584452]\n",
      "[-1.03326138  0.35585335]\n",
      "[-1.03323657  0.35586485]\n",
      "[-1.03320424  0.35586206]\n",
      "[-1.03321209  0.35584953]\n",
      "[-1.0332473   0.35584597]\n",
      "[-1.03325731  0.35585632]\n",
      "[-1.03322824  0.35586494]\n",
      "[-1.03320401  0.35585923]\n",
      "[-1.03322004  0.35584804]\n",
      "[-1.0332515   0.35584796]\n",
      "[-1.03325172  0.35585876]\n",
      "[-1.03322138  0.35586423]\n",
      "[-1.033206    0.35585652]\n",
      "[-1.03322767  0.35584736]\n",
      "[-1.03325339  0.35585025]\n",
      "[-1.03324528  0.35586055]\n",
      "[-1.03321633  0.35586291]\n",
      "[-1.0332097   0.35585412]\n",
      "[-1.03323441  0.35584744]\n",
      "[-1.03325318  0.35585261]\n",
      "[-1.03323864  0.35586166]\n",
      "[-1.03321322  0.35586118]\n",
      "[-1.03321457  0.35585218]\n",
      "Iteration ends......\n",
      "Solution has been found:  [-1.03321457  0.35585218]\n"
     ]
    }
   ],
   "source": [
    "gauss_jacobi(fun,x0 = np.array([0.1,0.1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d3283d",
   "metadata": {},
   "source": [
    "#### Gauss-Seidel algorithm\n",
    "- We seperately define each function, which leads to faster calculation speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ef426483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1(params):\n",
    "    x,y = params\n",
    "    return y-np.exp(x)\n",
    "\n",
    "def fun2(params):\n",
    "    x,y = params\n",
    "    return x * (x**2 - 3*y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "8f3cdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "aa8ba5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.1]\n",
      "[-0.80951626  0.15921943]\n",
      "[-1.45177873  0.43088663]\n",
      "[-0.61158941  0.27778358]\n",
      "[-1.09953457  0.34038783]\n",
      "[-1.07742883  0.3636694 ]\n",
      "[-1.00928889  0.35161204]\n",
      "[-1.04458876  0.35766697]\n",
      "[-1.02801717  0.35497004]\n",
      "[-1.0356923   0.35626144]\n",
      "[-1.03208394  0.3556636 ]\n",
      "[-1.03376853  0.35594469]\n",
      "[-1.03297961  0.35581349]\n",
      "[-1.03334852  0.35587494]\n",
      "[-1.03317589  0.35584621]\n",
      "[-1.03325664  0.35585965]\n",
      "[-1.03321886  0.35585336]\n",
      "[-1.03323654  0.3558563 ]\n",
      "Iteration ends......\n",
      "Solution has been found:  [-1.03322827  0.35585493]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def gauss_seidel(funs, x0 = np.array([0.1,0.1])):\n",
    "    fun1, fun2 = funs\n",
    "    epsilon = 1e-10\n",
    "    delta = 1e-10\n",
    "    x = np.array(x0, dtype=float)\n",
    "    grad_func1 = grad(fun1)\n",
    "    grad_func2 = grad(fun2)\n",
    "    s = np.zeros_like(x)\n",
    "    past_x = []\n",
    "    while True:\n",
    "        print(x)\n",
    "        past_x.append(x.copy())\n",
    "        f1x = fun1(x)\n",
    "        grad1 = grad_func1(x)\n",
    "        s[0] = f1x/grad1[0]\n",
    "        x[0] -= s[0]\n",
    "        grad2 = grad_func2(x)\n",
    "        f2x = fun2(x)\n",
    "        s[1] = f2x/grad2[1]\n",
    "        x[1] -= s[1]\n",
    "        # estimate rho_hat, the spectral radius of the Jacobian matrix\n",
    "        # 4-degree lag\n",
    "        if len(past_x)>5:\n",
    "            # to aviod accuracy loss, we additionally subtract 1e-5\n",
    "            b = max((((np.array(demo[-3:])/np.array(demo[-4:-1]) - 1e-5)**2)**2).sum(axis=1))\n",
    "            if (s**2).sum() < epsilon * b:\n",
    "                print('Iteration ends......')\n",
    "                if (fun1(x)**2 + fun2(x)**2) < delta:\n",
    "                    print('Solution has been found: ', x)\n",
    "                else:\n",
    "                    print('No solution has been found')\n",
    "                break\n",
    "\n",
    "# Find the zero\n",
    "gauss_seidel([fun1,fun2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018fbe08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
